{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda NVIDIA GeForce RTX 3090\n",
      "train num_puzzle_identifiers = 7290\n",
      "DEBUG AdamAtan2 LR: 0.0001 0.0001\n",
      "Loading ckpt: checkpoints/Exp6 ACT-torch/HierarchicalReasoningModel_ACTV1 righteous-reindeer/step_34164\n",
      "ckpt puzzle_emb shape: torch.Size([7290, 1024])\n",
      "model puzzle_emb shape: torch.Size([7290, 1024])\n",
      "Loaded checkpoint (strict=True) ✅\n",
      "\n",
      "[INPUT] 70+20=\n",
      "[OUTPUT] 回归预测值：99.67720794677734\n",
      "70+20= → 99.67720794677734\n",
      "\n",
      "[INPUT] 17+10=\n",
      "[OUTPUT] 回归预测值：52.33961486816406\n",
      "17+10= → 52.33961486816406\n",
      "\n",
      "[INPUT] 3+99=\n",
      "[OUTPUT] 回归预测值：31.51605796813965\n",
      "3+99= → 31.51605796813965\n",
      "\n",
      "[INPUT] 50+50=\n",
      "[OUTPUT] 回归预测值：106.71558380126953\n",
      "50+50= → 106.71558380126953\n"
     ]
    }
   ],
   "source": [
    "import os, yaml, gc\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- 基础环境设置 ----------\n",
    "os.environ[\"DISABLE_COMPILE\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"   # 按需改\n",
    "\n",
    "CKPT = \"checkpoints/Exp6 ACT-torch/HierarchicalReasoningModel_ACTV1 righteous-reindeer/step_34164\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\", torch.cuda.get_device_name(0) if device==\"cuda\" else \"\")\n",
    "\n",
    "# ---------- 导入工程内模块 ----------\n",
    "from pretrain import PretrainConfig, init_train_state, create_dataloader\n",
    "from mytokenizers.hf_math_tokenizer import HFMathTokenizer\n",
    "\n",
    "# =====================================================\n",
    "# 1. 加载配置和 train metadata，初始化模型\n",
    "# =====================================================\n",
    "ckpt_dir = os.path.dirname(CKPT)\n",
    "with open(os.path.join(ckpt_dir, \"all_config.yaml\"), \"r\") as f:\n",
    "    config = PretrainConfig(**yaml.safe_load(f))\n",
    "\n",
    "config.checkpoint_path = ckpt_dir\n",
    "RANK, WORLD_SIZE = 0, 1\n",
    "\n",
    "# ⚠️ 这里重点：用 TRAIN split 的 metadata，而不是 test\n",
    "train_loader, train_metadata = create_dataloader(\n",
    "    config,\n",
    "    split=\"train\",\n",
    "    test_set_mode=False,\n",
    "    epochs_per_iter=1,\n",
    "    global_batch_size=config.global_batch_size,\n",
    "    rank=RANK,\n",
    "    world_size=WORLD_SIZE,\n",
    ")\n",
    "\n",
    "print(\"train num_puzzle_identifiers =\", train_metadata.num_puzzle_identifiers)\n",
    "\n",
    "train_state = init_train_state(config, train_metadata, world_size=WORLD_SIZE)\n",
    "\n",
    "print(f\"Loading ckpt: {CKPT}\")\n",
    "raw_sd = torch.load(CKPT, map_location=device, weights_only=False)\n",
    "\n",
    "# =====================================================\n",
    "# 2. 清理 state_dict（只去掉 _orig_mod 前缀），不做截断修补\n",
    "# =====================================================\n",
    "def clean_state_dict(sd):\n",
    "    new_sd = {}\n",
    "    for k, v in sd.items():\n",
    "        new_k = k.replace(\"_orig_mod.\", \"\")\n",
    "        new_sd[new_k] = v\n",
    "    return new_sd\n",
    "\n",
    "sd = clean_state_dict(raw_sd)\n",
    "\n",
    "# 简单检查一下 puzzle_emb 大小\n",
    "model_sd = train_state.model.state_dict()\n",
    "if \"model.inner.puzzle_emb.weights\" in sd and \"model.inner.puzzle_emb.weights\" in model_sd:\n",
    "    print(\"ckpt puzzle_emb shape:\", sd[\"model.inner.puzzle_emb.weights\"].shape)\n",
    "    print(\"model puzzle_emb shape:\", model_sd[\"model.inner.puzzle_emb.weights\"].shape)\n",
    "\n",
    "try:\n",
    "    train_state.model.load_state_dict(sd, strict=True)\n",
    "    print(\"Loaded checkpoint (strict=True) ✅\")\n",
    "except RuntimeError as e:\n",
    "    print(\"❌ strict load failed, error如下，说明结构真不匹配：\")\n",
    "    print(e)\n",
    "    raise\n",
    "\n",
    "model = train_state.model.to(device).eval()\n",
    "\n",
    "# =====================================================\n",
    "# 3. HRM 专用 move_to_device（carry 也要搬）\n",
    "# =====================================================\n",
    "def move_to_device(obj, device):\n",
    "    if torch.is_tensor(obj):\n",
    "        return obj.to(device)\n",
    "\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return type(obj)(move_to_device(x, device) for x in obj)\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: move_to_device(v, device) for k, v in obj.items()}\n",
    "\n",
    "    if hasattr(obj, \"_fields\"):  # namedtuple\n",
    "        return type(obj)(*(move_to_device(getattr(obj, f), device) for f in obj._fields))\n",
    "\n",
    "    if hasattr(obj, \"__dict__\"):  # dataclass-like\n",
    "        for k, v in vars(obj).items():\n",
    "            setattr(obj, k, move_to_device(v, device))\n",
    "        return obj\n",
    "\n",
    "    return obj\n",
    "\n",
    "# =====================================================\n",
    "# 4. 加载 tokenizer\n",
    "# =====================================================\n",
    "tokenizer_path = \"data/MATH-401/exp6/saved_hf_tokenizer\"\n",
    "tokenizer = HFMathTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "def encode_expr(expr: str):\n",
    "    out = tokenizer(expr)\n",
    "    return torch.tensor(out[\"input_ids\"], dtype=torch.long)\n",
    "\n",
    "# =====================================================\n",
    "# 5. 单条表达式回归预测函数\n",
    "# =====================================================\n",
    "def predict_expr(expr: str) -> float:\n",
    "    print(f\"\\n[INPUT] {expr}\")\n",
    "\n",
    "    # 1) 从 train_loader 拿一个 batch，只取结构\n",
    "    train_iter = iter(train_loader)\n",
    "    _, batch, _ = next(train_iter)\n",
    "\n",
    "    # 2) 把第 0 条样本的 inputs 替换成我们要的表达式\n",
    "    ids = encode_expr(expr)\n",
    "    max_len = batch[\"inputs\"].shape[1]\n",
    "    if ids.shape[0] > max_len:\n",
    "        ids = ids[:max_len]\n",
    "\n",
    "    batch = {k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()}\n",
    "    batch[\"inputs\"][0].zero_()\n",
    "    batch[\"inputs\"][0, :ids.shape[0]] = ids\n",
    "\n",
    "    # label 不参与推理，用 0 占位\n",
    "    if \"labels\" in batch:\n",
    "        batch[\"labels\"][0].zero_()\n",
    "\n",
    "    # 3) 初始化 carry\n",
    "    carry = model.initial_carry(batch)\n",
    "    carry = move_to_device(carry, device)\n",
    "\n",
    "    # 4) 循环直到 ACT 停止，取回归预测 \"prediction\"\n",
    "    with torch.no_grad():\n",
    "        preds = None\n",
    "        while True:\n",
    "            carry = move_to_device(carry, device)\n",
    "            carry, _, _, preds, done = model(\n",
    "                carry=carry,\n",
    "                batch=batch,\n",
    "                return_keys=[\"prediction\"]\n",
    "            )\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "    pred_value = float(preds[\"prediction\"][0].item())\n",
    "    print(f\"[OUTPUT] 回归预测值：{pred_value}\")\n",
    "    return pred_value\n",
    "\n",
    "# =====================================================\n",
    "# 6. 简单测试\n",
    "# =====================================================\n",
    "# y = predict_expr(\"19+10=\")\n",
    "# print(\"预测结果：\", y)\n",
    "\n",
    "tests = [\"70+20=\", \"17+10=\", \"3+99=\", \"50+50=\"]\n",
    "\n",
    "for expr in tests:\n",
    "    y = predict_expr(expr)\n",
    "    print(f\"{expr} → {y}\")\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# =====================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 检查 Regression Head 预测质量\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# =====================================================\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m pred = \u001b[43mprediction\u001b[49m.detach().cpu().numpy()\n\u001b[32m      8\u001b[39m lbl = label.detach().cpu().numpy()\n\u001b[32m     10\u001b[39m mse = np.mean((pred - lbl) ** \u001b[32m2\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 检查 Regression Head 预测质量\n",
    "# =====================================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pred = prediction.detach().cpu().numpy()\n",
    "lbl = label.detach().cpu().numpy()\n",
    "\n",
    "mse = np.mean((pred - lbl) ** 2)\n",
    "mae = np.mean(np.abs(pred - lbl))\n",
    "maxe = np.max(np.abs(pred - lbl))\n",
    "\n",
    "print(\"\\n[Regression Evaluation]\")\n",
    "print(f\"MSE  = {mse:.4f}\")\n",
    "print(f\"MAE  = {mae:.4f}\")\n",
    "print(f\"MAXE = {maxe:.4f}\")\n",
    "\n",
    "print(\"\\nSample comparison (first 10):\")\n",
    "for i in range(10):\n",
    "    print(f\"{i:2d}: pred={pred[i]:8.3f}, label={lbl[i]:8.3f}, error={pred[i]-lbl[i]:+8.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrmpy311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
