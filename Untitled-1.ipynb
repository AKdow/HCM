{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81302/2496703087.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(os.path.join(checkpoint_path, \"pytorch_model.bin\"), map_location='cpu')\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: 'checkpoints/Exp4 ACT-torch/HierarchicalReasoningModel_ACTV1 happy-falcon/step_113900/pytorch_model.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotADirectoryError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m checkpoint_path = \u001b[33m\"\u001b[39m\u001b[33mcheckpoints/Exp4 ACT-torch/HierarchicalReasoningModel_ACTV1 happy-falcon/step_113900\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# åŠ è½½æ¨¡å‹æƒé‡\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpytorch_model.bin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mæ¨¡å‹ä¸­æ‰€æœ‰çš„é”®:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/serialization.py:1319\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1317\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1321\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1322\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1323\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1324\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/serialization.py:659\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    658\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    661\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/serialization.py:640\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mNotADirectoryError\u001b[39m: [Errno 20] Not a directory: 'checkpoints/Exp4 ACT-torch/HierarchicalReasoningModel_ACTV1 happy-falcon/step_113900/pytorch_model.bin'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# åŠ è½½checkpoint\n",
    "checkpoint_path = \"checkpoints/Exp4 ACT-torch/HierarchicalReasoningModel_ACTV1 happy-falcon/step_113900\"\n",
    "\n",
    "# åŠ è½½æ¨¡å‹æƒé‡\n",
    "checkpoint = torch.load(os.path.join(checkpoint_path, \"pytorch_model.bin\"), map_location='cpu')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"æ¨¡å‹ä¸­æ‰€æœ‰çš„é”®:\")\n",
    "print(\"=\" * 80)\n",
    "for key in checkpoint.keys():\n",
    "    print(f\"{key}: {checkpoint[key].shape if hasattr(checkpoint[key], 'shape') else type(checkpoint[key])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FFNç›¸å…³çš„å±‚:\")\n",
    "print(\"=\" * 80)\n",
    "for key in checkpoint.keys():\n",
    "    if 'ffn' in key.lower() or 'mlp' in key.lower() or 'fc' in key.lower():\n",
    "        print(f\"\\n{key}:\")\n",
    "        print(f\"  Shape: {checkpoint[key].shape}\")\n",
    "        print(f\"  Min: {checkpoint[key].min().item():.4f}, Max: {checkpoint[key].max().item():.4f}\")\n",
    "        print(f\"  Mean: {checkpoint[key].mean().item():.4f}, Std: {checkpoint[key].std().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ACT æ¨¡å‹æ¨ç† - å½»åº•ä¿®å¤è®¾å¤‡é—®é¢˜\n",
      "================================================================================\n",
      "\n",
      "1. åˆå§‹åŒ– tokenizer...\n",
      "âœ“ Tokenizer åˆå§‹åŒ–å®Œæˆ\n",
      "  - è¯æ±‡è¡¨å¤§å°: 41\n",
      "\n",
      "2. åŠ è½½é…ç½®...\n",
      "\n",
      "3. åŠ è½½æ£€æŸ¥ç‚¹...\n",
      "  âœ“ æ£€æµ‹åˆ°:\n",
      "    - vocab_size: 41\n",
      "    - num_puzzle_identifiers: 1\n",
      "\n",
      "4. åˆå§‹åŒ–æ¨¡å‹...\n",
      "âœ“ æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\n",
      "\n",
      "5. åŠ è½½æƒé‡...\n",
      "âœ“ æƒé‡åŠ è½½å®Œæˆ\n",
      "\n",
      "6. ä¿®å¤æ‰€æœ‰è®¾å¤‡é—®é¢˜...\n",
      "\n",
      "7. éªŒè¯è®¾å¤‡åˆ†é…...\n",
      "âœ… æ‰€æœ‰å¼ é‡å·²æ­£ç¡®åˆ†é…åˆ° GPU\n",
      "\n",
      "================================================================================\n",
      "8. å¼€å§‹æ¨ç†\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "é—®é¢˜: '10+10='\n",
      "============================================================\n",
      "  Tokenization: ['1', '0', '+', '1', '0', '='] â†’ [32, 31, 20, 32, 31, 25]\n",
      "  âŒ æ¨ç†å¤±è´¥: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "\n",
      "============================================================\n",
      "é—®é¢˜: '25+25='\n",
      "============================================================\n",
      "  Tokenization: ['2', '5', '+', '2', '5', '='] â†’ [33, 36, 20, 33, 36, 25]\n",
      "  âŒ æ¨ç†å¤±è´¥: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "\n",
      "============================================================\n",
      "é—®é¢˜: '100-50='\n",
      "============================================================\n",
      "  Tokenization: ['1', '0', '0', '-', '5', '0', '='] â†’ [32, 31, 31, 21, 36, 31, 25]\n",
      "  âŒ æ¨ç†å¤±è´¥: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "\n",
      "============================================================\n",
      "é—®é¢˜: '5*5='\n",
      "============================================================\n",
      "  Tokenization: ['5', '*', '5', '='] â†’ [36, 22, 36, 25]\n",
      "  âŒ æ¨ç†å¤±è´¥: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "\n",
      "================================================================================\n",
      "âœ… æ¨ç†å®Œæˆ!\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_81302/3741075158.py\", line 217, in <module>\n",
      "    carry, loss, metrics, preds, all_finish = model(\n",
      "                                              ^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/HRM-main/checkpoints/Exp4 ACT-torch/HierarchicalReasoningModel_ACTV1 happy-falcon/losses.py\", line 57, in forward\n",
      "    new_carry, outputs = self.model(**model_kwargs)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/HRM-main/models/hrm/hrm_act_v1.py\", line 250, in forward\n",
      "    new_inner_carry = self.inner.reset_carry(carry.halted, carry.inner_carry)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/HRM-main/models/hrm/hrm_act_v1.py\", line 180, in reset_carry\n",
      "    z_H=torch.where(reset_flag.view(-1, 1, 1), self.H_init, carry.z_H),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_81302/3741075158.py\", line 217, in <module>\n",
      "    carry, loss, metrics, preds, all_finish = model(\n",
      "                                              ^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/HRM-main/checkpoints/Exp4 ACT-torch/HierarchicalReasoningModel_ACTV1 happy-falcon/losses.py\", line 57, in forward\n",
      "    new_carry, outputs = self.model(**model_kwargs)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/HRM-main/models/hrm/hrm_act_v1.py\", line 250, in forward\n",
      "    new_inner_carry = self.inner.reset_carry(carry.halted, carry.inner_carry)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/HRM-main/models/hrm/hrm_act_v1.py\", line 180, in reset_carry\n",
      "    z_H=torch.where(reset_flag.view(-1, 1, 1), self.H_init, carry.z_H),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_81302/3741075158.py\", line 217, in <module>\n",
      "    carry, loss, metrics, preds, all_finish = model(\n",
      "                                              ^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/HRM-main/checkpoints/Exp4 ACT-torch/HierarchicalReasoningModel_ACTV1 happy-falcon/losses.py\", line 57, in forward\n",
      "    new_carry, outputs = self.model(**model_kwargs)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/HRM-main/models/hrm/hrm_act_v1.py\", line 250, in forward\n",
      "    new_inner_carry = self.inner.reset_carry(carry.halted, carry.inner_carry)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/HRM-main/models/hrm/hrm_act_v1.py\", line 180, in reset_carry\n",
      "    z_H=torch.where(reset_flag.view(-1, 1, 1), self.H_init, carry.z_H),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_81302/3741075158.py\", line 217, in <module>\n",
      "    carry, loss, metrics, preds, all_finish = model(\n",
      "                                              ^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/HRM-main/checkpoints/Exp4 ACT-torch/HierarchicalReasoningModel_ACTV1 happy-falcon/losses.py\", line 57, in forward\n",
      "    new_carry, outputs = self.model(**model_kwargs)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/miniconda3/envs/hrmpy311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/HRM-main/models/hrm/hrm_act_v1.py\", line 250, in forward\n",
      "    new_inner_carry = self.inner.reset_carry(carry.halted, carry.inner_carry)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wuzhou/pentafleet/b2312_/HRM-main/models/hrm/hrm_act_v1.py\", line 180, in reset_carry\n",
      "    z_H=torch.where(reset_flag.view(-1, 1, 1), self.H_init, carry.z_H),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# è®¾ç½®è·¯å¾„\n",
    "model_dir = \"checkpoints/Exp4 ACT-torch/HierarchicalReasoningModel_ACTV1 happy-falcon\"\n",
    "sys.path.insert(0, os.path.expanduser(\"~/HRM-main\"))\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ACT æ¨¡å‹æ¨ç† - å½»åº•ä¿®å¤è®¾å¤‡é—®é¢˜\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. å¯¼å…¥å¹¶åˆå§‹åŒ– tokenizer\n",
    "print(\"\\n1. åˆå§‹åŒ– tokenizer...\")\n",
    "from mytokenizers.hf_math_tokenizer import HFMathTokenizer\n",
    "\n",
    "tokenizer = HFMathTokenizer()\n",
    "print(f\"âœ“ Tokenizer åˆå§‹åŒ–å®Œæˆ\")\n",
    "print(f\"  - è¯æ±‡è¡¨å¤§å°: {tokenizer.vocab_size}\")\n",
    "\n",
    "# 2. åŠ è½½é…ç½®\n",
    "print(\"\\n2. åŠ è½½é…ç½®...\")\n",
    "config_path = os.path.join(model_dir, \"all_config.yaml\")\n",
    "with open(config_path, 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# 3. åŠ è½½æ£€æŸ¥ç‚¹\n",
    "print(\"\\n3. åŠ è½½æ£€æŸ¥ç‚¹...\")\n",
    "checkpoint_file = os.path.join(model_dir, \"step_113900\")\n",
    "state_dict = torch.load(checkpoint_file, map_location=\"cpu\", weights_only=False)\n",
    "cleaned_state_dict = {k.removeprefix(\"_orig_mod.\"): v for k, v in state_dict.items()}\n",
    "\n",
    "actual_vocab_size = cleaned_state_dict['model.inner.embed_tokens.embedding_weight'].shape[0]\n",
    "actual_num_puzzle_identifiers = cleaned_state_dict['model.inner.puzzle_emb.weights'].shape[0]\n",
    "\n",
    "print(f\"  âœ“ æ£€æµ‹åˆ°:\")\n",
    "print(f\"    - vocab_size: {actual_vocab_size}\")\n",
    "print(f\"    - num_puzzle_identifiers: {actual_num_puzzle_identifiers}\")\n",
    "\n",
    "# 4. æ„å»ºæ¨¡å‹é…ç½®\n",
    "model_config = {}\n",
    "if 'arch' in config_dict:\n",
    "    for key, value in config_dict['arch'].items():\n",
    "        if key == 'loss' and isinstance(value, dict):\n",
    "            for loss_key, loss_value in value.items():\n",
    "                model_config[loss_key] = loss_value\n",
    "        elif key != 'name':\n",
    "            model_config[key] = value\n",
    "\n",
    "REQUIRED_DEFAULTS = {\n",
    "    'batch_size': 1,\n",
    "    'seq_len': 512,\n",
    "    'vocab_size': actual_vocab_size,\n",
    "    'num_puzzle_identifiers': actual_num_puzzle_identifiers,\n",
    "    'rope_theta': 10000.0,\n",
    "    'halt_loss_weight': 0.01,\n",
    "}\n",
    "\n",
    "for field, default_value in REQUIRED_DEFAULTS.items():\n",
    "    if field not in model_config or field in ['vocab_size', 'num_puzzle_identifiers']:\n",
    "        model_config[field] = default_value\n",
    "\n",
    "if model_config.get('pos_encodings') == 'rope':\n",
    "    model_config['pos_encodings'] = 'learned'\n",
    "\n",
    "# 5. åˆå§‹åŒ–æ¨¡å‹\n",
    "print(\"\\n4. åˆå§‹åŒ–æ¨¡å‹...\")\n",
    "from models.hrm.hrm_act_v1 import HierarchicalReasoningModel_ACTV1\n",
    "from losses import ACTLossHead\n",
    "\n",
    "base_model = HierarchicalReasoningModel_ACTV1(model_config)\n",
    "loss_type = config_dict['arch']['loss'].get('loss_type', 'softmax_cross_entropy')\n",
    "model = ACTLossHead(base_model, loss_type=loss_type)\n",
    "\n",
    "print(f\"âœ“ æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\")\n",
    "\n",
    "# 6. åŠ è½½æƒé‡\n",
    "print(\"\\n5. åŠ è½½æƒé‡...\")\n",
    "missing_keys, unexpected_keys = model.load_state_dict(cleaned_state_dict, strict=False)\n",
    "print(\"âœ“ æƒé‡åŠ è½½å®Œæˆ\")\n",
    "\n",
    "# 7. ğŸ”§ è¶…çº§å¼ºåŠ›çš„è®¾å¤‡ä¿®å¤\n",
    "print(\"\\n6. ä¿®å¤æ‰€æœ‰è®¾å¤‡é—®é¢˜...\")\n",
    "\n",
    "def fix_all_devices(module, device='cuda'):\n",
    "    \"\"\"\n",
    "    é€’å½’åœ°å°†æ¨¡å—ä¸­çš„æ‰€æœ‰å¼ é‡ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡\n",
    "    åŒ…æ‹¬ï¼šå‚æ•°ã€ç¼“å†²åŒºã€ä»¥åŠæ‰€æœ‰ç±»å±æ€§ä¸­çš„å¼ é‡\n",
    "    \"\"\"\n",
    "    # 1. ç§»åŠ¨æ ‡å‡†å‚æ•°å’Œç¼“å†²åŒº\n",
    "    module.to(device)\n",
    "    \n",
    "    # 2. æ£€æŸ¥å¹¶ç§»åŠ¨æ‰€æœ‰å¯èƒ½çš„å¼ é‡å±æ€§\n",
    "    for attr_name in list(vars(module).keys()):  # ä½¿ç”¨ vars() è·å–å®ä¾‹å±æ€§\n",
    "        try:\n",
    "            attr = getattr(module, attr_name)\n",
    "            \n",
    "            # å¦‚æœæ˜¯å¼ é‡ï¼Œç§»åŠ¨å®ƒ\n",
    "            if isinstance(attr, torch.Tensor):\n",
    "                if attr.device.type != device:\n",
    "                    new_tensor = attr.to(device)\n",
    "                    setattr(module, attr_name, new_tensor)\n",
    "                    print(f\"  âœ“ ç§»åŠ¨ {module.__class__.__name__}.{attr_name} åˆ° {device}\")\n",
    "            \n",
    "            # å¦‚æœæ˜¯å¼ é‡åˆ—è¡¨æˆ–å…ƒç»„\n",
    "            elif isinstance(attr, (list, tuple)):\n",
    "                if attr and isinstance(attr[0], torch.Tensor):\n",
    "                    new_list = [t.to(device) if isinstance(t, torch.Tensor) else t for t in attr]\n",
    "                    setattr(module, attr_name, type(attr)(new_list))\n",
    "                    print(f\"  âœ“ ç§»åŠ¨ {module.__class__.__name__}.{attr_name} (å®¹å™¨) åˆ° {device}\")\n",
    "            \n",
    "            # å¦‚æœæ˜¯å­—å…¸\n",
    "            elif isinstance(attr, dict):\n",
    "                new_dict = {}\n",
    "                for k, v in attr.items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        new_dict[k] = v.to(device)\n",
    "                    else:\n",
    "                        new_dict[k] = v\n",
    "                if new_dict != attr:\n",
    "                    setattr(module, attr_name, new_dict)\n",
    "                    print(f\"  âœ“ ç§»åŠ¨ {module.__class__.__name__}.{attr_name} (å­—å…¸) åˆ° {device}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            # å¿½ç•¥æ— æ³•è®¿é—®çš„å±æ€§\n",
    "            pass\n",
    "    \n",
    "    # 3. é€’å½’å¤„ç†å­æ¨¡å—\n",
    "    for child in module.children():\n",
    "        fix_all_devices(child, device)\n",
    "\n",
    "fix_all_devices(model, 'cuda')\n",
    "\n",
    "# 8. éªŒè¯æ‰€æœ‰å¼ é‡éƒ½åœ¨ GPU ä¸Š\n",
    "print(\"\\n7. éªŒè¯è®¾å¤‡åˆ†é…...\")\n",
    "\n",
    "all_tensors_ok = True\n",
    "\n",
    "# æ£€æŸ¥å‚æ•°\n",
    "for name, param in model.named_parameters():\n",
    "    if param.device.type != 'cuda':\n",
    "        print(f\"  âš ï¸ å‚æ•° {name} ä»åœ¨ {param.device}\")\n",
    "        all_tensors_ok = False\n",
    "\n",
    "# æ£€æŸ¥ç¼“å†²åŒº\n",
    "for name, buffer in model.named_buffers():\n",
    "    if buffer.device.type != 'cuda':\n",
    "        print(f\"  âš ï¸ ç¼“å†²åŒº {name} ä»åœ¨ {buffer.device}\")\n",
    "        all_tensors_ok = False\n",
    "\n",
    "# æ£€æŸ¥ç‰¹æ®Šå±æ€§ (é€’å½’)\n",
    "def check_module_tensors(module, prefix=\"\"):\n",
    "    for attr_name in list(vars(module).keys()):\n",
    "        try:\n",
    "            attr = getattr(module, attr_name)\n",
    "            if isinstance(attr, torch.Tensor) and attr.device.type != 'cuda':\n",
    "                print(f\"  âš ï¸ å±æ€§ {prefix}.{attr_name} ä»åœ¨ {attr.device}\")\n",
    "                return False\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for child_name, child in module.named_children():\n",
    "        if not check_module_tensors(child, f\"{prefix}.{child_name}\"):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "if check_module_tensors(model, \"model\"):\n",
    "    if all_tensors_ok:\n",
    "        print(\"âœ… æ‰€æœ‰å¼ é‡å·²æ­£ç¡®åˆ†é…åˆ° GPU\")\n",
    "else:\n",
    "    all_tensors_ok = False\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 9. æ¨ç†æµ‹è¯•\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"8. å¼€å§‹æ¨ç†\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_problems = [\n",
    "    \"10+10=\",\n",
    "    \"25+25=\",\n",
    "    \"100-50=\",\n",
    "    \"5*5=\",\n",
    "]\n",
    "\n",
    "for problem in test_problems:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"é—®é¢˜: '{problem}'\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # ä½¿ç”¨ tokenizer ç¼–ç \n",
    "    tokens = tokenizer.tokenize(problem)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    \n",
    "    print(f\"  Tokenization: {tokens} â†’ {token_ids}\")\n",
    "    \n",
    "    # å‡†å¤‡è¾“å…¥\n",
    "    tokens_tensor = torch.tensor([token_ids], dtype=torch.long).cuda()\n",
    "    \n",
    "    batch = {\n",
    "        'inputs': tokens_tensor,\n",
    "        'puzzle_identifiers': torch.zeros(1, dtype=torch.long).cuda(),\n",
    "    }\n",
    "    \n",
    "    # æ¨ç†\n",
    "    max_iterations = model_config.get('halt_max_steps', 16)\n",
    "    all_outputs = []\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            carry = model.initial_carry(batch)\n",
    "            \n",
    "            for step in range(max_iterations):\n",
    "                carry, loss, metrics, preds, all_finish = model(\n",
    "                    return_keys=['logits'],\n",
    "                    carry=carry,\n",
    "                    batch=batch,\n",
    "                )\n",
    "                \n",
    "                if 'logits' in preds:\n",
    "                    all_outputs.append(preds['logits'].cpu())\n",
    "                \n",
    "                if all_finish:\n",
    "                    print(f\"  âœ“ åœ¨ç¬¬ {step+1} æ­¥åœæ­¢\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"  âš ï¸ è¾¾åˆ°æœ€å¤§æ­¥æ•° {max_iterations}\")\n",
    "        \n",
    "        # è§£ç ç»“æœ\n",
    "        if all_outputs:\n",
    "            final_logits = all_outputs[-1]\n",
    "            predictions = final_logits.argmax(dim=-1)[0]\n",
    "            \n",
    "            # è§£ç \n",
    "            pred_ids = predictions.tolist()\n",
    "            valid_pred_ids = []\n",
    "            \n",
    "            for pid in pred_ids[:20]:\n",
    "                if pid < actual_vocab_size and pid not in [\n",
    "                    tokenizer.pad_token_id,\n",
    "                    tokenizer.unk_token_id,\n",
    "                ]:\n",
    "                    valid_pred_ids.append(pid)\n",
    "                elif pid != tokenizer.pad_token_id:\n",
    "                    break\n",
    "            \n",
    "            pred_tokens = [tokenizer.id_to_token.get(pid, '<?>') for pid in valid_pred_ids]\n",
    "            answer = ''.join(pred_tokens)\n",
    "            \n",
    "            print(f\"  é¢„æµ‹: {problem}{answer}\")\n",
    "            \n",
    "            # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡\n",
    "            if metrics:\n",
    "                key_metrics = ['halt_mean_n_updates', 'halt_act_loss']\n",
    "                for k in key_metrics:\n",
    "                    if k in metrics:\n",
    "                        v = metrics[k]\n",
    "                        if isinstance(v, torch.Tensor):\n",
    "                            print(f\"    {k}: {v.item():.4f}\")\n",
    "        else:\n",
    "            print(\"  âŒ æ²¡æœ‰ç”Ÿæˆè¾“å‡º\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ æ¨ç†å¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… æ¨ç†å®Œæˆ!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "DEBUG AdamAtan2 LR: 5e-05 5e-05\n",
      "å‘ç° 8 ä¸ªå¯èƒ½çš„ FFN/MLP æ¨¡å—ï¼š\n",
      "  [00] inner.H_level.layers.0.mlp\n",
      "  [01] inner.H_level.layers.1.mlp\n",
      "  [02] inner.H_level.layers.2.mlp\n",
      "  [03] inner.H_level.layers.3.mlp\n",
      "  [04] inner.L_level.layers.0.mlp\n",
      "  [05] inner.L_level.layers.1.mlp\n",
      "  [06] inner.L_level.layers.2.mlp\n",
      "  [07] inner.L_level.layers.3.mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97033/2544568372.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(CKPT, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "å®Œæˆå‰å‘ï¼Œå…± 16 ä¸ª segmentï¼›å·²æ•è· FFN è¾“å‡ºå¼ é‡ï¼š\n",
      " - inner.L_level.layers.0.mlp: å…± 64 æ¬¡ï¼Œç¤ºä¾‹å½¢çŠ¶ [(128, 10, 512), (128, 10, 512)]\n",
      " - inner.L_level.layers.1.mlp: å…± 64 æ¬¡ï¼Œç¤ºä¾‹å½¢çŠ¶ [(128, 10, 512), (128, 10, 512)]\n",
      " - inner.L_level.layers.2.mlp: å…± 64 æ¬¡ï¼Œç¤ºä¾‹å½¢çŠ¶ [(128, 10, 512), (128, 10, 512)]\n",
      " - inner.L_level.layers.3.mlp: å…± 64 æ¬¡ï¼Œç¤ºä¾‹å½¢çŠ¶ [(128, 10, 512), (128, 10, 512)]\n",
      " - inner.H_level.layers.0.mlp: å…± 32 æ¬¡ï¼Œç¤ºä¾‹å½¢çŠ¶ [(128, 10, 512), (128, 10, 512)]\n",
      " - inner.H_level.layers.1.mlp: å…± 32 æ¬¡ï¼Œç¤ºä¾‹å½¢çŠ¶ [(128, 10, 512), (128, 10, 512)]\n",
      " - inner.H_level.layers.2.mlp: å…± 32 æ¬¡ï¼Œç¤ºä¾‹å½¢çŠ¶ [(128, 10, 512), (128, 10, 512)]\n",
      " - inner.H_level.layers.3.mlp: å…± 32 æ¬¡ï¼Œç¤ºä¾‹å½¢çŠ¶ [(128, 10, 512), (128, 10, 512)]\n",
      "\n",
      "ç¤ºä¾‹åˆ‡ç‰‡ï¼ˆç¬¬ä¸€å±‚ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼Œbatch[0], tokens[:4], hidden[:8]ï¼‰ï¼š\n",
      "tensor([[-0.6523,  0.5625, -0.2676, -1.0469, -0.1582,  0.3574,  0.7734, -1.1250],\n",
      "        [-0.2617,  0.0491,  0.2637,  0.1318,  0.4414,  0.2852, -0.3418, -0.1816],\n",
      "        [-0.3203,  4.9688, -1.6406,  3.5938, -4.0312,  3.6719, -3.0000, -1.3438],\n",
      "        [-0.5859, -2.1406,  4.3750, -1.8984, -1.2578, -3.7656,  5.5312, -6.8125]])\n",
      "\n",
      "âœ… FFN è¾“å‡ºæ•è·å®Œæˆï¼Œå¯ç”¨ captured['å±‚å'] æŸ¥çœ‹å…·ä½“å¼ é‡ã€‚\n"
     ]
    }
   ],
   "source": [
    "# === A. æ‰“å° FFN/MLP å±‚è¾“å‡ºï¼ˆä¿®æ­£ç‰ˆï¼Œæ”¯æŒGPU carryï¼‰ ===\n",
    "import os, yaml, re, gc\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# é¿å… torch.compile å¸¦æ¥çš„é™æ€å›¾é—®é¢˜\n",
    "os.environ[\"DISABLE_COMPILE\"] = \"1\"\n",
    "\n",
    "from pretrain import PretrainConfig, init_train_state, create_dataloader\n",
    "\n",
    "# === 1) åŸºæœ¬é…ç½®ï¼šä¿®æ”¹ä¸ºä½ è‡ªå·±çš„ checkpoint è·¯å¾„ ===\n",
    "CKPT = \"checkpoints/Exp4 ACT-torch/HierarchicalReasoningModel_ACTV1 happy-falcon/step_113900\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# === 2) åŠ è½½é…ç½®å’Œæ¨¡å‹ ===\n",
    "ckpt_dir = os.path.dirname(CKPT)\n",
    "with open(os.path.join(ckpt_dir, \"all_config.yaml\"), \"r\") as f:\n",
    "    cfg_dict = yaml.safe_load(f)\n",
    "config = PretrainConfig(**cfg_dict)\n",
    "config.checkpoint_path = ckpt_dir\n",
    "\n",
    "RANK, WORLD_SIZE = 0, 1\n",
    "eval_loader, eval_metadata = create_dataloader(\n",
    "    config, split=\"test\", test_set_mode=True, epochs_per_iter=1,\n",
    "    global_batch_size=config.global_batch_size, rank=RANK, world_size=WORLD_SIZE\n",
    ")\n",
    "train_state = init_train_state(config, eval_metadata, world_size=WORLD_SIZE)\n",
    "\n",
    "# === 3) åŠ è½½ checkpoint ===\n",
    "sd = torch.load(CKPT, map_location=device)\n",
    "try:\n",
    "    train_state.model.load_state_dict(sd, assign=True)\n",
    "except Exception:\n",
    "    train_state.model.load_state_dict({k.replace(\"_orig_mod.\", \"\"): v for k, v in sd.items()}, assign=True)\n",
    "train_state.model.eval().to(device)\n",
    "\n",
    "# === 4) è‡ªåŠ¨è¯†åˆ« FFN/MLP å±‚ ===\n",
    "def looks_like_ffn(name: str, module: nn.Module):\n",
    "    n = name.lower()\n",
    "    cls = module.__class__.__name__.lower()\n",
    "    hit_name = any(tag in n for tag in [\"ffn\", \"mlp\", \"feedforward\", \"ff_block\", \"ff\"])\n",
    "    hit_cls  = any(tag in cls for tag in [\"ffn\", \"mlp\", \"feed\", \"gatedmlp\"])\n",
    "    return hit_name or hit_cls\n",
    "\n",
    "ffn_modules = []\n",
    "backbone = getattr(train_state.model, \"model\", train_state.model)\n",
    "for name, mod in backbone.named_modules():\n",
    "    if looks_like_ffn(name, mod) and len(list(mod.children())) > 0:\n",
    "        ffn_modules.append((name, mod))\n",
    "\n",
    "print(f\"å‘ç° {len(ffn_modules)} ä¸ªå¯èƒ½çš„ FFN/MLP æ¨¡å—ï¼š\")\n",
    "for i,(n,_) in enumerate(ffn_modules):\n",
    "    print(f\"  [{i:02d}] {n}\")\n",
    "\n",
    "# åªæŠ“éƒ¨åˆ†å±‚ï¼ˆå¯é€‰ï¼‰\n",
    "SELECTED = None\n",
    "if SELECTED is not None:\n",
    "    ffn_modules = [ffn_modules[i] for i in SELECTED]\n",
    "\n",
    "# æ³¨å†Œ forward hook\n",
    "captured = defaultdict(list)\n",
    "hooks = []\n",
    "for name, mod in ffn_modules:\n",
    "    def make_hook(layer_name):\n",
    "        def _hook(m, inp, out):\n",
    "            try:\n",
    "                captured[layer_name].append(out.detach().float().cpu())\n",
    "            except Exception:\n",
    "                pass\n",
    "        return _hook\n",
    "    hooks.append(mod.register_forward_hook(make_hook(name)))\n",
    "\n",
    "# === 5) è¾…åŠ©å‡½æ•°ï¼šæŠŠ carry ç§»åˆ° GPU ===\n",
    "def move_to_device(obj, device):\n",
    "    if torch.is_tensor(obj):\n",
    "        return obj.to(device)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: move_to_device(v, device) for k, v in obj.items()}\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        t = [move_to_device(v, device) for v in obj]\n",
    "        return type(obj)(t)\n",
    "    elif hasattr(obj, '_fields'):  # namedtuple\n",
    "        return type(obj)(*(move_to_device(v, device) for v in obj))\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        for k,v in vars(obj).items():\n",
    "            setattr(obj, k, move_to_device(v, device))\n",
    "        return obj\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# === 6) å‰å‘å¹¶æ•è· FFN è¾“å‡º ===\n",
    "with torch.inference_mode():\n",
    "    set_name, batch, global_bs = next(iter(eval_loader))\n",
    "    batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
    "\n",
    "    carry = train_state.model.initial_carry(batch)\n",
    "    carry = move_to_device(carry, device)\n",
    "\n",
    "    step_cnt = 0\n",
    "    while True:\n",
    "        carry, _, metrics, preds, all_finish = train_state.model(\n",
    "            carry=carry, batch=batch, return_keys=[]\n",
    "        )\n",
    "        step_cnt += 1\n",
    "        if all_finish:\n",
    "            break\n",
    "\n",
    "print(f\"\\nå®Œæˆå‰å‘ï¼Œå…± {step_cnt} ä¸ª segmentï¼›å·²æ•è· FFN è¾“å‡ºå¼ é‡ï¼š\")\n",
    "for name,vlist in captured.items():\n",
    "    shapes = [tuple(x.shape) for x in vlist[:2]]\n",
    "    print(f\" - {name}: å…± {len(vlist)} æ¬¡ï¼Œç¤ºä¾‹å½¢çŠ¶ {shapes}\")\n",
    "\n",
    "# æ‰“å°ä¸€ä¸ªç¤ºä¾‹åˆ‡ç‰‡\n",
    "if len(ffn_modules):\n",
    "    first_name = list(captured.keys())[0]\n",
    "    sample = captured[first_name][0]\n",
    "    print(\"\\nç¤ºä¾‹åˆ‡ç‰‡ï¼ˆç¬¬ä¸€å±‚ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼Œbatch[0], tokens[:4], hidden[:8]ï¼‰ï¼š\")\n",
    "    print(sample[0, :4, :8])\n",
    "\n",
    "# æ¸…ç†\n",
    "for h in hooks: h.remove()\n",
    "del sd, sample, batch, carry\n",
    "gc.collect()\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nâœ… FFN è¾“å‡ºæ•è·å®Œæˆï¼Œå¯ç”¨ captured['å±‚å'] æŸ¥çœ‹å…·ä½“å¼ é‡ã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device -> cuda\n",
      "DEBUG AdamAtan2 LR: 5e-05 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_105622/1802374878.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(CKPT, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 candidate FFN/MLP modules.\n",
      "  [00] inner.H_level.layers.0.mlp\n",
      "  [01] inner.H_level.layers.1.mlp\n",
      "  [02] inner.H_level.layers.2.mlp\n",
      "  [03] inner.H_level.layers.3.mlp\n",
      "  [04] inner.L_level.layers.0.mlp\n",
      "  [05] inner.L_level.layers.1.mlp\n",
      "  [06] inner.L_level.layers.2.mlp\n",
      "  [07] inner.L_level.layers.3.mlp\n",
      "Carry devices after move: {'cuda:0'}\n",
      "Forward done: 16 segments. Captured FFN outputs:\n",
      " - inner.L_level.layers.0.mlp: count=64, example_shapes=[(256, 65, 512), (256, 65, 512)]\n",
      " - inner.L_level.layers.1.mlp: count=64, example_shapes=[(256, 65, 512), (256, 65, 512)]\n",
      " - inner.L_level.layers.2.mlp: count=64, example_shapes=[(256, 65, 512), (256, 65, 512)]\n",
      " - inner.L_level.layers.3.mlp: count=64, example_shapes=[(256, 65, 512), (256, 65, 512)]\n",
      " - inner.H_level.layers.0.mlp: count=32, example_shapes=[(256, 65, 512), (256, 65, 512)]\n",
      " - inner.H_level.layers.1.mlp: count=32, example_shapes=[(256, 65, 512), (256, 65, 512)]\n",
      " - inner.H_level.layers.2.mlp: count=32, example_shapes=[(256, 65, 512), (256, 65, 512)]\n",
      " - inner.H_level.layers.3.mlp: count=32, example_shapes=[(256, 65, 512), (256, 65, 512)]\n",
      "Target text: 10+10=\n",
      "Carry devices (B step) after move: {'cuda:0'}\n",
      "\n",
      "=== æ¨¡å‹åœ¨ '10+10=' ä¹‹åçš„ Top-10 é¢„æµ‹ ===\n",
      " 1. token_id=    40  p=1.0000  -> '40'\n",
      " 2. token_id=     1  p=0.0000  -> '1'\n",
      " 3. token_id=     3  p=0.0000  -> '3'\n",
      " 4. token_id=     6  p=0.0000  -> '6'\n",
      " 5. token_id=     7  p=0.0000  -> '7'\n",
      " 6. token_id=     0  p=0.0000  -> '0'\n",
      " 7. token_id=     2  p=0.0000  -> '2'\n",
      " 8. token_id=     5  p=0.0000  -> '5'\n",
      " 9. token_id=     8  p=0.0000  -> '8'\n",
      "10. token_id=     4  p=0.0000  -> '4'\n",
      "\n",
      "è¿ç»­ç”Ÿæˆ 3 æ­¥ -> '404040'\n",
      "\n",
      "âœ… è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚captured å­—å…¸ä¸­åŒ…å« FFN è¾“å‡ºï¼›Top-k å·²æ‰“å°ã€‚\n"
     ]
    }
   ],
   "source": [
    "# Combined script: æŠ“å– FFN è¾“å‡º + åœ¨ batch ä¸­å†™å…¥ \"10+10=\" å¹¶æŸ¥çœ‹ logits\n",
    "# Paste into a Jupyter cell and run. Change CKPT to your checkpoint file.\n",
    "\n",
    "import os, yaml, re, gc, json, numpy as np\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# å¦‚æœä½ çš„ç¯å¢ƒä¼šä½¿ç”¨ torch.compileï¼Œæš‚æ—¶ç¦ç”¨å®ƒä»¥é¿å…é™æ€å›¾é™åˆ¶\n",
    "os.environ[\"DISABLE_COMPILE\"] = \"1\"\n",
    "\n",
    "# === --------------- ç”¨æˆ·ä¿®æ”¹é¡¹ --------------- ===\n",
    "CKPT = \"checkpoints/Exp5 ACT-torch/HierarchicalReasoningModel_ACTV1 pragmatic-barracuda/step_56940\"\n",
    "# ===============================================\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device -> {device}\")\n",
    "\n",
    "# Import project-specific helpers (assumes you can import pretrain from repo root)\n",
    "from pretrain import PretrainConfig, init_train_state, create_dataloader\n",
    "\n",
    "# ---------- åŠ è½½é…ç½®ã€æ•°æ®ã€æ¨¡å‹ ----------\n",
    "ckpt_dir = os.path.dirname(CKPT)\n",
    "with open(os.path.join(ckpt_dir, \"all_config.yaml\"), \"r\") as f:\n",
    "    cfg_dict = yaml.safe_load(f)\n",
    "config = PretrainConfig(**cfg_dict)\n",
    "config.checkpoint_path = ckpt_dir\n",
    "\n",
    "RANK, WORLD_SIZE = 0, 1\n",
    "eval_loader, eval_metadata = create_dataloader(\n",
    "    config, split=\"test\", test_set_mode=True, epochs_per_iter=1,\n",
    "    global_batch_size=config.global_batch_size, rank=RANK, world_size=WORLD_SIZE\n",
    ")\n",
    "train_state = init_train_state(config, eval_metadata, world_size=WORLD_SIZE)\n",
    "\n",
    "# åŠ è½½ checkpointï¼ˆå…¼å®¹ _orig_mod å‰ç¼€ï¼‰\n",
    "sd = torch.load(CKPT, map_location=\"cpu\")\n",
    "try:\n",
    "    train_state.model.load_state_dict(sd, assign=True)\n",
    "except Exception:\n",
    "    train_state.model.load_state_dict({k.replace(\"_orig_mod.\", \"\"): v for k, v in sd.items()}, assign=True)\n",
    "\n",
    "train_state.model.eval().to(device)\n",
    "backbone = getattr(train_state.model, \"model\", train_state.model)\n",
    "\n",
    "# ---------- é€šç”¨å·¥å…·ï¼šé€’å½’ç§»åŠ¨åˆ° deviceï¼Œæ£€æŸ¥è®¾å¤‡é›†åˆ ----------\n",
    "def move_to_device(obj, device):\n",
    "    \"\"\"Recursively move tensor-containing objects to device.\"\"\"\n",
    "    if torch.is_tensor(obj):\n",
    "        return obj.to(device)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: move_to_device(v, device) for k, v in obj.items()}\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        converted = [move_to_device(v, device) for v in obj]\n",
    "        return type(obj)(converted)\n",
    "    elif hasattr(obj, \"_fields\"):  # namedtuple\n",
    "        return type(obj)(*(move_to_device(v, device) for v in obj))\n",
    "    elif hasattr(obj, \"__dict__\"):\n",
    "        for k, v in vars(obj).items():\n",
    "            setattr(obj, k, move_to_device(v, device))\n",
    "        return obj\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "def device_set(obj):\n",
    "    \"\"\"Return set of devices found inside obj's tensors (as strings).\"\"\"\n",
    "    devs = set()\n",
    "    if torch.is_tensor(obj):\n",
    "        devs.add(str(obj.device))\n",
    "    elif isinstance(obj, dict):\n",
    "        for v in obj.values():\n",
    "            devs |= device_set(v)\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        for v in obj:\n",
    "            devs |= device_set(v)\n",
    "    elif hasattr(obj, \"_fields\"):\n",
    "        for v in obj:\n",
    "            devs |= device_set(v)\n",
    "    elif hasattr(obj, \"__dict__\"):\n",
    "        for v in vars(obj).values():\n",
    "            devs |= device_set(v)\n",
    "    return devs\n",
    "\n",
    "# ---------- A) æŠ“å– FFN/MLP å±‚è¾“å‡º ----------\n",
    "def looks_like_ffn(name: str, module: nn.Module):\n",
    "    n = name.lower()\n",
    "    cls = module.__class__.__name__.lower()\n",
    "    hit_name = any(tag in n for tag in [\"ffn\", \"mlp\", \"feedforward\", \"ff_block\", \"ff\"])\n",
    "    hit_cls  = any(tag in cls for tag in [\"ffn\", \"mlp\", \"feed\", \"gatedmlp\"])\n",
    "    return hit_name or hit_cls\n",
    "\n",
    "ffn_modules = []\n",
    "for name, mod in backbone.named_modules():\n",
    "    if looks_like_ffn(name, mod) and len(list(mod.children())) > 0:\n",
    "        ffn_modules.append((name, mod))\n",
    "\n",
    "print(f\"Found {len(ffn_modules)} candidate FFN/MLP modules.\")\n",
    "for i, (n, _) in enumerate(ffn_modules):\n",
    "    print(f\"  [{i:02d}] {n}\")\n",
    "\n",
    "# å¦‚æœå±‚å¾ˆå¤šï¼Œç”¨æˆ·å¯ä»¥æ‰‹å·¥é€‰æ‹©ã€‚None è¡¨ç¤ºå…¨éƒ¨\n",
    "SELECTED = None\n",
    "if SELECTED is not None:\n",
    "    ffn_modules = [ffn_modules[i] for i in SELECTED]\n",
    "\n",
    "captured = defaultdict(list)\n",
    "hooks = []\n",
    "for name, mod in ffn_modules:\n",
    "    def make_hook(layer_name):\n",
    "        def _hook(m, inp, out):\n",
    "            try:\n",
    "                captured[layer_name].append(out.detach().float().cpu())\n",
    "            except Exception:\n",
    "                pass\n",
    "        return _hook\n",
    "    hooks.append(mod.register_forward_hook(make_hook(name)))\n",
    "\n",
    "# å–ä¸€ä¸ª eval batch å¹¶å‰å‘ï¼ˆä¿è¯ batch åœ¨ device ä¸Šï¼‰\n",
    "eval_iter = iter(eval_loader)\n",
    "set_name, batch, _ = next(eval_iter)\n",
    "batch = {k: (v.to(device, non_blocking=True) if torch.is_tensor(v) else v) for k, v in batch.items()}\n",
    "\n",
    "# åˆå§‹åŒ– carryï¼Œå¹¶ç¡®ä¿å…¨éƒ¨åœ¨ device ä¸Š\n",
    "carry = train_state.model.initial_carry(batch)\n",
    "carry = move_to_device(carry, device)\n",
    "print(\"Carry devices after move:\", device_set(carry))\n",
    "\n",
    "# å‰å‘è‹¥å¹² segmentï¼ˆæŒ‰ç…§æ¨¡å‹ evaluate çš„å¾ªç¯ï¼‰\n",
    "with torch.inference_mode():\n",
    "    step_cnt = 0\n",
    "    while True:\n",
    "        carry, _, metrics, preds, all_finish = train_state.model(carry=carry, batch=batch, return_keys=[])\n",
    "        step_cnt += 1\n",
    "        if all_finish:\n",
    "            break\n",
    "\n",
    "print(f\"Forward done: {step_cnt} segments. Captured FFN outputs:\")\n",
    "for name, vlist in captured.items():\n",
    "    shapes = [tuple(x.shape) for x in vlist[:2]]\n",
    "    print(f\" - {name}: count={len(vlist)}, example_shapes={shapes}\")\n",
    "\n",
    "# æ¸…é™¤ hooks\n",
    "for h in hooks:\n",
    "    h.remove()\n",
    "\n",
    "# ---------- B) åœ¨ batch[0] å†™å…¥ \"10+10=\"ï¼ŒæŸ¥çœ‹ç­‰å·åä¸€ä¸ªä½ç½®çš„ Top-K logits ----------\n",
    "def build_encoder_decoder(eval_loader, metadata, data_path):\n",
    "    ds = getattr(eval_loader, \"dataset\", None)\n",
    "    cand_objs = [ds, metadata, backbone]\n",
    "    for obj in cand_objs:\n",
    "        if obj is None: continue\n",
    "        if hasattr(obj, \"encode\"):\n",
    "            enc = getattr(obj, \"encode\")\n",
    "            dec = getattr(obj, \"decode\", None)\n",
    "            return enc, dec\n",
    "        for name in [\"tokenizer\", \"vocab\", \"encoder\"]:\n",
    "            if hasattr(obj, name):\n",
    "                tok = getattr(obj, name)\n",
    "                if hasattr(tok, \"encode\"):\n",
    "                    return tok.encode, getattr(tok, \"decode\", None)\n",
    "                if isinstance(tok, dict):\n",
    "                    stoi = tok.get(\"stoi\") or tok.get(\"char2id\") or tok.get(\"token_to_id\")\n",
    "                    itos = tok.get(\"itos\") or tok.get(\"id2char\") or tok.get(\"id_to_token\")\n",
    "                    if stoi:\n",
    "                        def enc_fn(s): return [stoi.get(ch, stoi.get(\"<unk>\", 0)) for ch in s]\n",
    "                        def dec_fn(ids): \n",
    "                            if itos: return \"\".join(itos.get(int(i), \"?\") for i in ids)\n",
    "                            return \"\".join(\"?\")\n",
    "                        return enc_fn, dec_fn\n",
    "    if data_path and os.path.isdir(data_path):\n",
    "        for fn in os.listdir(data_path):\n",
    "            if re.search(r\"vocab|stoi|itos|token\", fn, re.I):\n",
    "                p = os.path.join(data_path, fn)\n",
    "                try:\n",
    "                    if fn.endswith(\".json\"):\n",
    "                        with open(p, \"r\") as f:\n",
    "                            obj = json.load(f)\n",
    "                        if isinstance(obj, dict):\n",
    "                            stoi = obj\n",
    "                            itos = {v:k for k,v in stoi.items()}\n",
    "                            def enc_fn(s): return [stoi.get(ch, stoi.get(\"<unk>\", 0)) for ch in s]\n",
    "                            def dec_fn(ids): return \"\".join(itos.get(int(i), \"?\") for i in ids)\n",
    "                            return enc_fn, dec_fn\n",
    "                    elif fn.endswith(\".txt\"):\n",
    "                        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "                            tokens = [line.rstrip(\"\\n\") for line in f]\n",
    "                        stoi = {tok:i for i,tok in enumerate(tokens)}\n",
    "                        itos = {i:tok for tok,i in stoi.items()}\n",
    "                        def enc_fn(s): return [stoi.get(ch, stoi.get(\"<unk>\", 0)) for ch in s]\n",
    "                        def dec_fn(ids): return \"\".join(itos.get(int(i), \"?\") for i in ids)\n",
    "                        return enc_fn, dec_fn\n",
    "                except Exception:\n",
    "                    pass\n",
    "    def fallback_encode(s):\n",
    "        vocab_size = getattr(eval_metadata, \"vocab_size\", 256)\n",
    "        return [ord(ch) % vocab_size for ch in s]\n",
    "    return fallback_encode, None\n",
    "\n",
    "enc_fn, dec_fn = build_encoder_decoder(eval_loader, eval_metadata, getattr(config, \"data_path\", None))\n",
    "\n",
    "# é‡æ–°å–ä¸€ä¸ª batchï¼ˆfresh iteratorï¼‰\n",
    "eval_iter = iter(eval_loader)\n",
    "set_name, batch, _ = next(eval_iter)\n",
    "# æŠŠ tensor å­—æ®µç§»åˆ° deviceï¼Œå¹¶ clone é˜²æ­¢ä¿®æ”¹åŸæ•°æ®ç»“æ„\n",
    "batch = {k: (v.to(device).clone() if torch.is_tensor(v) else v) for k, v in batch.items()}\n",
    "\n",
    "target_text = \"10+10=\"\n",
    "print(\"Target text:\", target_text)\n",
    "ids = enc_fn(target_text)\n",
    "ids = torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "# æ‰¾ inputs keyï¼ˆå¸¸è§ \"inputs\"ï¼‰\n",
    "inputs_key = \"inputs\" if \"inputs\" in batch else next(iter(batch.keys()))\n",
    "x = batch[inputs_key]  # expect [B, T] or similar\n",
    "if not torch.is_tensor(x):\n",
    "    raise RuntimeError(f\"Batch inputs {inputs_key} is not a tensor; got {type(x)}\")\n",
    "\n",
    "B, T = x.shape[0], x.shape[1] if x.dim() >= 2 else (x.shape[0],)\n",
    "assert ids.numel() <= T, f\"è¡¨è¾¾å¼é•¿åº¦({ids.numel()})è¶…è¿‡æ¨¡å‹åºåˆ—é•¿åº¦({T})\"\n",
    "\n",
    "# çŒœæµ‹ pad idï¼ˆç»éªŒæ³•ï¼‰\n",
    "def guess_pad_id(x_tensor):\n",
    "    tail = x_tensor[:, int(0.75*T):].reshape(-1).cpu().numpy()\n",
    "    if tail.size == 0: return None\n",
    "    vals, cnts = np.unique(tail, return_counts=True)\n",
    "    pad = int(vals[np.argmax(cnts)])\n",
    "    return pad\n",
    "\n",
    "pad_id = guess_pad_id(batch[inputs_key])\n",
    "\n",
    "# åœ¨ batch çš„ç¬¬ä¸€æ¡å†™å…¥ ids\n",
    "x0 = x[0].clone()\n",
    "x0[:ids.numel()] = ids.to(x0.device)\n",
    "if pad_id is not None:\n",
    "    x0[ids.numel():] = pad_id\n",
    "x[0] = x0\n",
    "batch[inputs_key] = x\n",
    "\n",
    "# åŒæ­¥å¯èƒ½å­˜åœ¨çš„é•¿åº¦/mask å­—æ®µ\n",
    "for k in [\"input_lens\", \"lengths\", \"seq_lens\"]:\n",
    "    if k in batch and torch.is_tensor(batch[k]):\n",
    "        batch[k][0] = ids.numel()\n",
    "for k in [\"attention_mask\", \"attn_mask\", \"mask\"]:\n",
    "    if k in batch and torch.is_tensor(batch[k]):\n",
    "        mask = batch[k][0]\n",
    "        if mask.dim() == 1:\n",
    "            mask[:ids.numel()] = 1\n",
    "            mask[ids.numel():] = 0\n",
    "        elif mask.dim() == 2:\n",
    "            mask[:ids.numel(), :ids.numel()] = 1\n",
    "            mask[ids.numel():, :] = 0\n",
    "            mask[:, ids.numel():] = 0\n",
    "        batch[k][0] = mask\n",
    "\n",
    "# å‰å‘ä¸€æ¬¡æ‹¿ logitsï¼ˆå¹¶ä¿è¯ carry åœ¨ deviceï¼‰\n",
    "with torch.inference_mode():\n",
    "    carry = train_state.model.initial_carry(batch)\n",
    "    carry = move_to_device(carry, device)\n",
    "    print(\"Carry devices (B step) after move:\", device_set(carry))\n",
    "    while True:\n",
    "        carry, _, metrics, preds, all_finish = train_state.model(carry=carry, batch=batch, return_keys=[\"logits\"])\n",
    "        if all_finish:\n",
    "            break\n",
    "\n",
    "if \"logits\" not in preds:\n",
    "    raise RuntimeError(\"preds does not contain 'logits' key. Check model's return_keys / head implementation.\")\n",
    "\n",
    "logits = preds[\"logits\"]  # expect shape [B, T, V]\n",
    "pos = ids.numel()  # position just after '10+10='\n",
    "if pos >= logits.shape[1]:\n",
    "    raise RuntimeError(f\"Requested pos {pos} >= seq length {logits.shape[1]}\")\n",
    "\n",
    "logit_pos = logits[0, pos]  # [V]\n",
    "prob = logit_pos.float().softmax(dim=-1)\n",
    "topk = torch.topk(prob, k=min(10, prob.numel()))\n",
    "top_ids = topk.indices.tolist()\n",
    "top_p   = topk.values.tolist()\n",
    "\n",
    "def safe_decode_one(tid):\n",
    "    if dec_fn is None:\n",
    "        return str(tid)\n",
    "    try:\n",
    "        ch = dec_fn([tid])\n",
    "        if isinstance(ch, list):\n",
    "            ch = \"\".join(map(str, ch))\n",
    "        return ch\n",
    "    except Exception:\n",
    "        return str(tid)\n",
    "\n",
    "print(\"\\n=== æ¨¡å‹åœ¨ '10+10=' ä¹‹åçš„ Top-10 é¢„æµ‹ ===\")\n",
    "for rank, (tid, p) in enumerate(zip(top_ids, top_p), 1):\n",
    "    print(f\"{rank:2d}. token_id={tid:>6}  p={p:.4f}  -> '{safe_decode_one(tid)}'\")\n",
    "\n",
    "# å¯é€‰ï¼šç»§ç»­ç”Ÿæˆå‡ æ­¥ï¼ˆargmax æ–¹å¼ï¼‰\n",
    "steps = 3\n",
    "cur = ids.clone()\n",
    "gen = []\n",
    "with torch.inference_mode():\n",
    "    for i in range(steps):\n",
    "        # æ¯æ­¥æŠŠ cur å†™å› batchï¼Œç„¶å initial_carry -> forward -> å– logits\n",
    "        gen_batch = {k: (v.clone() if torch.is_tensor(v) else v) for k, v in batch.items()}\n",
    "        x = gen_batch[inputs_key]\n",
    "        x[0, :cur.numel()] = cur.to(x.device)\n",
    "        if pad_id is not None:\n",
    "            x[0, cur.numel():] = pad_id\n",
    "        gen_batch[inputs_key] = x\n",
    "\n",
    "        carry = train_state.model.initial_carry(gen_batch)\n",
    "        carry = move_to_device(carry, device)\n",
    "        while True:\n",
    "            carry, _, _, preds, all_finish = train_state.model(carry=carry, batch=gen_batch, return_keys=[\"logits\"])\n",
    "            if all_finish:\n",
    "                break\n",
    "        nxt = preds[\"logits\"][0, cur.numel()].argmax(dim=-1).item()\n",
    "        gen.append(nxt)\n",
    "        cur = torch.cat([cur, torch.tensor([nxt], dtype=torch.long)])\n",
    "\n",
    "decoded = \"\".join(safe_decode_one(t) for t in gen)\n",
    "print(f\"\\nè¿ç»­ç”Ÿæˆ {steps} æ­¥ -> '{decoded}'\")\n",
    "\n",
    "# æ¸…ç†æ˜¾å­˜\n",
    "del sd, batch, carry, preds\n",
    "gc.collect()\n",
    "if device.startswith(\"cuda\"):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nâœ… è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚captured å­—å…¸ä¸­åŒ…å« FFN è¾“å‡ºï¼›Top-k å·²æ‰“å°ã€‚\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrmpy311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
